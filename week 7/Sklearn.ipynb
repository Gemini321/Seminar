{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning (Sklearn)\n",
    "Scikit-learn(sklearn)是机器学习中常用的第三方模块，对常用的机器学习方法进行了封装，包括回归(Regression)、降维(Dimensionality Reduction)、分类(Classfication)、聚类(Clustering)等方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入Sklearn数据集\n",
    "sklearn中包含了大量数据集，可以根据不同的数据集选择不同的模型。\n",
    "![Alt](https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171029151405930-1982232117.png)\n",
    "![jupyter](https://images2017.cnblogs.com/blog/1251096/201710/1251096-20171029151424867-594200677.png)\n",
    "还可用样本生成器创建数据集，详见[样本生成器](https://blog.csdn.net/yuanshuaipeng/article/details/80399863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例子\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris() # 导入数据集\n",
    "X = iris.data # 获得其特征向量\n",
    "y = iris.target # 获得样本label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "### 1.数据归一化（将数据标准统一）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.70710678 -0.70710678]\n",
      " [-0.70710678 -0.70710678]\n",
      " [ 1.41421356  1.41421356]]\n",
      "[[1.41421356 1.41421356]\n",
      " [3.53553391 7.77817459]\n",
      " [5.65685425 9.89949494]]\n",
      "\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]]\n",
      "[[0.   0.  ]\n",
      " [0.5  0.75]\n",
      " [1.   1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1], [2, 4], [3, 5]]\n",
    "train_data = data[:3]\n",
    "test_data = data[3:]\n",
    "# 1. 基于mean和std的标准化\n",
    "scaler = preprocessing.StandardScaler().fit(train_data)\n",
    "train_data = scaler.transform(train_data)\n",
    "test_data = scaler.transform(test_data)\n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print()\n",
    "\n",
    "# 2. 将每个特征值归一化到一个固定范围（例子为(0, 1)）\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test_data)\n",
    "#feature_range: 定义归一化范围，注用（）括起来\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.正则化\n",
    "当你想要计算两个样本的**相似度**时必不可少的一个操作，就是正则化。其思想是：首先求出样本的**p-范数**（$res = \\sqrt[p]{\\sum_{i=0}^nx_i^p}$），然后该样本的所有元素都要除以该范数，这样最终使得每个样本的范数都为1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40824829 -0.40824829  0.81649658]\n",
      " [ 1.          0.          0.        ]\n",
      " [ 0.          0.70710678 -0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "x = [[1., -1., 2.], [2., 0., 0.], [0., 1., -1.]]\n",
    "x_normalized = preprocessing.normalize(x, norm='l2')\n",
    "print(x_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.one-hot编码\n",
    "one-hot编码是一种对离散特征值的编码方式，在LR模型中常用到，用于给线性模型增加非线性能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]]\n",
    "encoder = preprocessing.OneHotEncoder().fit(data)\n",
    "data = encoder.transform(data).toarray()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集拆分\n",
    "在得到训练数据集时，通常我们经常会把训练数据集进一步拆分成训练集和测试集，这样有助于我们模型参数的选取。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 作用：将数据集划分为 训练集和测试集\n",
    "# 格式：train_test_split(*arrays, **options)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split # 比例为7:3；random_state为随机种子\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型\n",
    "在这一步我们首先要分析自己数据的类型，搞清出你要用什么模型来做，然后我们就可以在sklearn中定义模型了。sklearn为所有模型提供了非常相似的接口，这样使得我们可以更加快速的熟悉所有模型的用法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-eb7832cb6a39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 拟合模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 模型预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model需要自己定义\n",
    "# 拟合模型\n",
    "model.fit(X_train, y_train)\n",
    "# 模型预测\n",
    "model.predict(X_test)\n",
    "\n",
    "# 获得这个模型的参数\n",
    "model.get_params()\n",
    "# 为模型进行打分\n",
    "model.score(data_X, data_y) # 线性回归：R square； 分类问题： acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n参数\\n---\\n    fit_intercept：是否计算截距。False-模型没有截距\\n    normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\\n     n_jobs：指定线程数\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# 定义线性回归模型\n",
    "model = LinearRegression(fit_intercept=True, normalize=False, \n",
    "    copy_X=True, n_jobs=1)\n",
    "\"\"\"\n",
    "参数\n",
    "---\n",
    "    fit_intercept：是否计算截距。False-模型没有截距\n",
    "    normalize： 当fit_intercept设置为False时，该参数将被忽略。 如果为真，则回归前的回归系数X将通过减去平均值并除以l2-范数而归一化。\n",
    "     n_jobs：指定线程数\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.逻辑回归LR\n",
    "### 3.朴素贝叶斯算法NB\n",
    "### 4.决策树DT\n",
    "### 5.随机森林算法\n",
    "    随机森林算法是一种集成算法，相当于许多棵决策树进行投票，可以显著改善单棵决策树的过拟合性\n",
    "### 5.k近邻算法KNN\n",
    "### 6.多层感知机（神经网络）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"参数\\n---\\n    model：拟合数据的模型\\n    cv ： k-fold\\n    scoring: 打分参数-‘accuracy’、‘f1’、‘precision’、‘recall’ 、‘roc_auc’、'neg_log_loss'等等\\n\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(model, X, y, scoring=None, cv=None, n_jobs=1)\n",
    "\"\"\"参数\n",
    "---\n",
    "    model：拟合数据的模型\n",
    "    cv ： k-fold\n",
    "    scoring: 打分参数-‘accuracy’、‘f1’、‘precision’、‘recall’ 、‘roc_auc’、'neg_log_loss'等等\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.验证曲线\n",
    "使用检验曲线，我们可以更加方便地改变模型参数，获取模型表现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'param_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-f2382c88f0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvalidation_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \"\"\"参数\n\u001b[0;32m      4\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m用于fit和predict的对象\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'param_name' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "train_score, test_score = validation_curve(model, X, y, param_name, param_range, cv=None, scoring=None, n_jobs=1)\n",
    "\"\"\"参数\n",
    "---\n",
    "    model:用于fit和predict的对象\n",
    "    X, y: 训练集的特征和标签\n",
    "    param_name：将被改变的参数的名字\n",
    "    param_range： 参数的改变范围\n",
    "    cv：k-fold\n",
    "   \n",
    "返回值\n",
    "---\n",
    "   train_score: 训练集得分（array）\n",
    "    test_score: 验证集得分（array）\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型（略）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完整Machine Learning实现请看[Machine Learning实现过程](https://cloud.tencent.com/developer/article/1469086)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
